#!/bin/bash
# Runs mst experiments on Arya
# This should be run in the easy-parallel-graph/autoperf/mst directory

USAGE="usage: ./run generate_data|experiment|parse|all
	. run build <------ do this one first"
# source run build to get the environment variables to stick.

# Parse command line options
cmd="$1"
if [ -z "$cmd" -o "$cmd" = "-h" -o "$cmd" = "--help" ]; then
	echo "$USAGE"
	return 2
elif [ "$cmd" != generate_data -a "$cmd" != experiment -a "$cmd" != build -a "$cmd" != all -a "$cmd" != parse ]; then
	echo "Invalid argument $cmd"
	echo "$USAGE"
	return 2
fi

# Initialization
# These should all be the same as what's available in autoperf.cfg.
# This is why some are exported and you must source run build
LIB_DIR="$(pwd)/lib"
module load tau # Also loads the PAPI environment variable
export POWER_PROFILING=1
export TAU_MAKEFILE="$TAU_DIR/x86_64/lib/Makefile.tau-papi-pdt-openmp" # I don't think this is needed when sampling
export DDIR=/home/users/spollard/graphalytics/all-datasets/PBBSInput
PBBS_DIR="$LIB_DIR/pbbs-msf/minSpanningForest"
XPS_DIR="$LIB_DIR/xpscode/MSTSC"
GALOIS_DIR="$LIB_DIR/Galois-2.2.1"
ROOTDIR="$(pwd)/output"
OMP_NUM_THREADS=72 
export OMP_NUM_THREADS
EPV=8 # Edges per vertex
ENSURE_CONNECTED='no' # yes if you want to run bfs.out
RT_TYPES="ER B G"
INS_PCTAGES="10 25 50 75 90 100"
CHANGED_VERTICES="1000 2000 5000"
SCALES="20" # 23 24 25 26 27" # Make sure to have SCALES be the same as what's in autoperf.cfg

# Define commands to be run
generate_data()
{
	echo "Downloading datasets. May take a while..." # LOG
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-friendster.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-orkut.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-lj.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/soc-pokec-relationships.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/wiki-Talk.txt.gz
	wget -nc -P "$DDIR" http://string-db.org/download/protein.links.v10.txt.gz

	# Download or generate Mew MST graph files
	# Right now we just generate them on the fly
	# wget -nc -P "$DDIR" http://brix.d.cs.uoregon.edu/graphs/rmat{20..27}8_{B,G,ER}.gr.gz
	# echo "Unzipping files..."
	# for RT in $RT_TYPES; do
	# 	for S in $SCALES; do
	# 		gunzip -c "$DDIR/rmat${S}${EPV}_${RT}.gr.gz" | awk '{printf "%d %d %d\n",$1,$2,int(rand()*100)}' > "$DDIR/rmat${S}${EPV}_${RT}-orig.wel"
	# 		"$GALOIS_DIR/build/release/tools/graph-convert/graph-convert" -intedgelist2gr "$DDIR/rmat${S}${EPV}_${RT}-orig.wel" "$DDIR/rmat${S}${EPV}_${RT}-orig.wel"
	# 	done
	# done
	cd "$XPS_DIR"
	echo "Generating RMAT files..."
	for INS_PCT in $INS_PCTAGES; do
		for CVERTS in $CHANGED_VERTICES; do
			for RT in $RT_TYPES; do
				for S in $SCALES; do
					echo -e "~~~~~\nGenerating scale $S, $EPV edges per vertex, RMAT $RT, $INS_PCT% insertions, $CVERTS changed vertices\n~~~~~" # LOG
					if [ "$RT" = ER ]; then # Just do this once
						"$XPS_DIR/../RMAT/driverForRmat" $S 6 $EPV 0.45 0.15 0.15 0.25 "$DDIR/rmat${S}${EPV}_G-orig.wel"
						"$XPS_DIR/../RMAT/driverForRmat" $S 6 $EPV 0.55 0.15 0.15 0.15 "$DDIR/rmat${S}${EPV}_B-orig.wel"
						"$XPS_DIR/../RMAT/driverForRmat" $S 6 $EPV 0.25 0.25 0.25 0.25 "$DDIR/rmat${S}${EPV}_ER-orig.wel"
					fi
					mv "$DDIR/rmat${S}${EPV}_${RT}-orig.wel" tmp
					awk '{printf "%d %d %d\n", $1, $2, int(rand()*100)}' tmp > "$DDIR/rmat${S}${EPV}_${RT}-orig.wel"
					rm tmp
					"$XPS_DIR/tEx.out" "$DDIR/rmat${S}${EPV}_${RT}-orig.wel" $(awk '{print $1; exit}' "$DDIR/rmat${S}${EPV}_${RT}-orig.wel")
					# tEx.out generates Graph*x.txt, bfs.out generates Graph*.txt
					if [ "$ENSURE_CONNECTED" = 'yes' ]; then
						"$XPS_DIR/bfs.out" "$XPS_DIR/GraphCx.txt" $(awk '{print $1; exit}' "$XPS_DIR/GraphCx.txt")
						rm "$XPS_DIR/Graphallx.txt" # May not be connected
						mv "$XPS_DIR/Graphall.txt" "$DDIR/rmat${S}${EPV}_${RT}.wel"
						rm "$XPS_DIR/GraphCx.txt" # Duplicate
						mv "$XPS_DIR/GraphC.txt" "$DDIR/rmat${S}${EPV}_${RT}.cert"
						rm "$XPS_DIR/Graphdiff.txt" # Empty
					else	
						mv "$XPS_DIR/Graphallx.txt" "$DDIR/rmat${S}${EPV}_${RT}.wel"
						mv "$XPS_DIR/GraphCx.txt" "$DDIR/rmat${S}${EPV}_${RT}.cert"
					fi
					mv "$XPS_DIR/Graphdiffx.txt" "$DDIR/rmat${S}${EPV}_${RT}.diff"
					"$XPS_DIR/cE.out" "$DDIR/rmat${S}${EPV}_${RT}.wel" ${CVERTS} 100 $INS_PCT > "$DDIR/changedrmat${S}${EPV}_${RT}_${INS_PCT}i_${CVERTS}"
					sort -n -k1 -k2 "$DDIR/changedrmat${S}${EPV}_${RT}_${INS_PCT}i_${CVERTS}" > "$DDIR/changedrmat${S}${EPV}_${RT}_${INS_PCT}i_${CVERTS}S"
					awk -f "$LIB_DIR/../change_edgelist.awk" -v CEL="$DDIR/changedrmat${S}${EPV}_${RT}_${INS_PCT}i_${CVERTS}S" "$DDIR/rmat${S}${EPV}_${RT}.wel" > "$DDIR/rmat${S}${EPV}_${RT}-${INS_PCT}i_${CVERTS}.wel"
					"$GALOIS_DIR/build/release/tools/graph-convert/graph-convert" -intedgelist2gr "$DDIR/rmat${S}${EPV}_${RT}-${INS_PCT}i_${CVERTS}.wel" "$DDIR/rmat${S}${EPV}_${RT}-${INS_PCT}i_${CVERTS}.gr"
				done
			done
		done
	done
	cd "$LIB_DIR/.."
}

build_autoperf()
{
	if [ -z "$SQLITE3" ]; then
		echo "You may need SQLITE3 environment variable for autoperf. Trying to get it with dpkg..."
		export SQLITE3=$(dirname $(dpkg -L libsqlite3-dev | grep .so)) # Needed for autoperf
		if [ -z "$SQLITE3" ]; then
			echo "Unable to find libsqlite3 shared object file"
			echo "Try installing libsqlite3-dev or -devel"
			return 1
		fi
	fi
	if [ -z "$PAPI" ]; then
		echo "Please set the PAPI environment variable"
		return 1
	fi
	# Download autoperf and add it to your PATH
	AUTOPERF_LOC=$(command -v autoperf) # Check if autoperf is already in path
	if [ $? -ne 0 ]; then
		echo "Installing autoperf"
		git clone https://github.com/HPCL/autoperf.git "$HOME/autoperf"
		cd "$HOME/autoperf"
		python setup.py install --user
	else
		echo "found autoperf at $AUTOPERF_LOC"
	fi
}

build_Galois()
{
	# XXX: This probably won't work for anyone else.
	#
	# This must be added to the CMakeLists.txt:
	# if(POWER_PROFILING)
	#   message(STATUS "Compiling for power measurement using RAPL")
	#   set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DPOWER_PROFILING=1 -L${PAPI}/lib -Wl,-rpath,${PAPI}/lib")
	#   set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -DPOWER_PROFILING=1 -L${PAPI}/lib -Wl,-rpath,${PAPI}/lib")
	#   include_directories("${PAPI}/include")
	# endif()
	#
	# Replace apps/boruvka/CMakeLists.txt with the following:
	# app(boruvka Boruvka.cpp power_rapl.c power_rapl.h
	#   EXTLIBS papi)
	# app(boruvka-merge BoruvkaMerge.cpp)
	
	# Replace
	# Assumes Galois is already downloaded and unzippeed into GALOIS_DIR
	# This can be found at
	# http://iss.ices.utexas.edu/projects/galois/downloads/Galois-2.2.1.tar.gz
	# The newer the version of boost, the newer you must have of cmake
    # module load boost-1.63.0-gcc-4.8-hucoocn
	module load boost/boost_1_53_0_gcc-4.8
	# Copy from easy-parallel-graph's RAPL wrappers.
	cp "$LIB_DIR/../../../power/power_rapl.c" "$GALOIS_DIR/apps/boruvka"
	cp "$LIB_DIR/../../../power/power_rapl.h" "$GALOIS_DIR/apps/boruvka"
    cd "$GALOIS_DIR/build"
	mkdir -p power
	cd power
    cmake -DCMAKE_Fortran_COMPILER=gfortran-4.8 -DPOWER_PROFILING=1 -DPAPI="$PAPI" -Wno-dev ../../ 
}

build_PBBS()
{
	echo "building PBBS..."
	mkdir -p "$PBBS_DIR"
	wget -nc -P "$PBBS_DIR/.." http://www.cs.cmu.edu/~pbbs/benchmarks/minSpanningForest.tar 
	if [ ! -d minSpanningForest ]; then
		tar -xf minSpanningForest.tar
	fi
	cd minSpanningForest/parallelKruskal
	make
	cd "$LIB_DIR/.."
}

# Build XPS. This also sort of generates the data (though derived from the previous datasets)
build_XPS()
{
	git clone https://github.com/HPCL/xpscode.git "$LIB_DIR/xpscode" # Requires authentication
	cd "$XPS_DIR"
	ESSENSPATH="$LIB_DIR/xpscode/ESSENS"
	# Use vim syntax to edit the Makefile so it has the correct path to ESSENS
	ex -s Makefile "+:%s?^ESSENS=.*?ESSENS=$ESSENSPATH?g" '+:wq' # XXX: Will the * cause problems?
	# Turn on power monitoring (CFLAGS is used in c++ code too in this makefile)
	RAPL_DIR="$LIB_DIR/../../../power"
	POWER_CFLAGS="-w -I$PAPI/include -I$RAPL_DIR -DPOWER_PROFILING=1"
	RAPL_INC="power_rapl.o $RAPL_DIR/power_rapl.h -L$PAPI/lib -Wl,-rpath,$PAPI/lib -lpapi"
	gcc -c $POWER_CFLAGS "$RAPL_DIR/power_rapl.c" -o power_rapl.o
	make CFLAGS="$POWER_CFLAGS" RAPL_INC="$RAPL_INC" all # This only builds the mst update executable (a.out)
	make cE
	make tEx
	make bfs
}

run_autoperf()
{
	# FOR EXAMPLE...
	# TODO: Loop over these in a reasonable way, make AUTOPERF_NUM_THREADS actually done in autoperf.
	AUTOPERF_SCALE=20
	AUTOPERF_CHANGED_EDGES=500
	AUTOPERF_MAX_WEIGHT=100
	AUTOPERF_NUM_VERTICES=$(echo '2 ^ ' $AUTOPERF_SCALE | bc)
	AUTOPERF_EDGES_PER_VERTEX=8 # XXX: Keep this at 8 for now
	AUTOPERF_NUM_THREADS=4

	# NOTE: When using ex you cannot also have that program open in vim or else it will hang
	cp autoperf.cfg .autoperf.cfg # Autoperf searches for .autoperf.cfg first
	ex -s .autoperf.cfg "+:%s/AUTOPERF_SCALE/$AUTOPERF_SCALE/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_CHANGED_EDGES/$AUTOPERF_CHANGED_EDGES/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_MAX_WEIGHT/$AUTOPERF_MAX_WEIGHT/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_NUM_VERTICES/$AUTOPERF_NUM_VERTICES/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_EDGES_PER_VERTEX/$AUTOPERF_EDGES_PER_VERTEX/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_NUM_THREADS/$AUTOPERF_NUM_THREADS/g" '+:wq'
	# autoperf
}

# FIXME Does not take into account CVERTS nor INS_PCT
run_experiment()
{
	echo "Running the experiment..."
	cd "$ROOTDIR" # So we can just print output to cwd
	OMP_NUM_THREADS=72
	export OMP_NUM_THREADS
	RT=ER # RMAT type: ER->(.25,.25,.25,.25) G->(.45, .15, .15, .25) B->(.55, .15, .15, .15)
	for S in $SCALES; do
		N_VERT=$(echo 2 ^ $S | bc)
		sudo "$GALOIS_DIR/build/power/apps/boruvka/boruvka" -t=$OMP_NUM_THREADS "$DDIR/rmat${S}${EPV}_${RT}.gr" | tee "$ROOTDIR/galois-${S}${EPV}_$RT.log"
		# ./a.out <diff_file> <certificate> <set of changed edges> <upper bound of edge weight> <number of vertices>  <number of threads>
		sudo "$XPS_DIR/a.out" "$DDIR/rmat${S}${EPV}_${RT}.diff" "$DDIR/rmat${S}${EPV}_${RT}.cert" "$DDIR/changedrmat${S}${EPV}_${RT}_500S" 100 $N_VERT $OMP_NUM_THREADS | tee "$ROOTDIR/mst-${S}${EPV}_$RT.log"
		sudo chown spollard "$ROOTDIR/mst-${S}${EPV}_$RT.log"
		sudo chown spollard "$ROOTDIR/galois-${S}${EPV}_$RT.log"
	done
	cd "$LIB_DIR/.."
}

parse_output()
{
	echo "Parsing output..."
	cd "$ROOTDIR" # So we can just print output to cwd
	PFN="$ROOTDIR/parsed-power-$OMP_NUM_THREADS.txt"
	RT=ER # RMAT type: ER->(.25,.25,.25,.25) G->(.45, .15, .15, .25) B->(.55, .15, .15, .15)
	PKG=2
	GRANULARITY=WT # Options: WT or Main
	# Only using main, less to parse
	for S in $SCALES; do
		if [ "$GRANULARITY" = Main ]; then
			awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,All,%s_%s_%s,Total CPU Energy (J),%s\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' mst-${S}${EPV}_$RT.log >> "$PFN"
			awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,All,%s_%s_%s,Average CPU Power (W),%s\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' mst-${S}${EPV}_$RT.log >> "$PFN"
			awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,All,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' mst-${S}${EPV}_$RT.log >> "$PFN"
		elif [ "$GRANULARITY" = WT ]; then
			grep -A 30 'Starting create_tree' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,create_tree,%s_%s_%s,Total CPU Energy (J),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			grep -A 30 'Starting create_tree' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,create_tree,%s_%s_%s,Average CPU Power (W),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			grep -A 30 'Starting create_tree' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,create_tree,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' >> "$PFN"

			grep -A 30 'Starting first_pass' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,first_pass,%s_%s_%s,Total CPU Energy (J),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			grep -A 30 'Starting first_pass' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,first_pass,%s_%s_%s,Average CPU Power (W),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			grep -A 30 'Starting first_pass' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,first_pass,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' >> "$PFN"

			grep -A 30 'Starting process_insertions' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,process_insertions,%s_%s_%s,Total CPU Energy (J),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			grep -A 30 'Starting process_insertions' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,process_insertions,%s_%s_%s,Average CPU Power (W),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			grep -A 30 'Starting process_insertions' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,process_insertions,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' >> "$PFN"

			grep -B 31 'Time for Deletion' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,process_deletions,%s_%s_%s,Total CPU Energy (J),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			grep -B 31 'Time for Deletion' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,process_deletions,%s_%s_%s,Average CPU Power (W),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			grep -B 31 'Time for Deletion' mst-${S}${EPV}_$RT.log | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,process_deletions,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' >> "$PFN"
		fi
		awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "Galois,All,%s_%s_%s,Total CPU Energy (J),%s\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' galois-${S}${EPV}_$RT.log >> "$PFN"
		awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "Galois,All,%s_%s_%s,Average CPU Power (W),%s\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' galois-${S}${EPV}_$RT.log >> "$PFN"
		awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "Galois,All,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' galois-${S}${EPV}_$RT.log >> "$PFN"
	done
}

if [ "$cmd" = generate_data -o "$cmd" = all ]; then
	generate_data
fi
if [ "$cmd" = build -o "$cmd" = all ]; then
	build_autoperf
    build_Galois
	# build_PBBS
	build_XPS
	cd "$LIB_DIR/.."
fi

if [ "$cmd" = parse -o "$cmd" = all ]; then
	parse_output
fi

if [ "$cmd" = experiment -o "$cmd" = all ]; then
	# run_autoperf
	run_experiment
fi

