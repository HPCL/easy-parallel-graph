#!/bin/bash
# Runs autoperf experiments on Arya
# NOTE: You may need to execute
#       . run build
# To get the environment variables to stick.
# TODO: Add editing of autoperf.cfg to shell script? Or can we just export DDIR and stuff and be okay?

USAGE="usage: ./run generate_data|autoperf|all
	. run build"

# Parse command line options
cmd="$1"
if [ -z "$cmd" -o "$cmd" = "-h" -o "$cmd" = "--help" ]; then
	echo "$USAGE"
	return 2
fi

# Initialization
LIB_DIR="$(pwd)/lib"
module load tau # Also loads PAPI
export TAU_MAKEFILE="$TAU_DIR/x86_64/lib/Makefile.tau-papi-openmp"
export DDIR=/home/users/spollard/graphalytics/all-datasets/PBBSInput
PBBS_DIR="$LIB_DIR/pbbs-msf/minSpanningForest"
SCALES="16 18 20" # Make sure to have SCALES be the same as what's in autoperf.cfg

# Define commands to be run
generate_data()
{
	for S in $SCALES; do
		echo "Creating weighted rmat with 2^$S vertices and ~16 x 2^$S edges" # LOG
		N=$(echo 2 ^ $S | bc)
		M=$(echo $N '* 16' | bc)
		EG_FILE="$DDIR/rmat$S.eg"
		WEG_FILE="$DDIR/rmat$S.weg"
		if [ ! -r "$WEG_FILE" ]; then
			"$PBBS_DIR/graphData/rMatGraph" -a 0.57 -b 0.19 -c 0.19 -d 0.05 -m $M $N $EG_FILE
			"$PBBS_DIR/graphData/addWeights" $EG_FILE $WEG_FILE
			echo "saved to $DDIR/rmat$S.weg" # LOG
			tail -n+2 "$DDIR/rmat$S.weg" > "$DDIR/rmat$S.wel"
			echo "saved to $DDIR/rmat$S.wel" # LOG
		else
			echo "file already exists at $DDIR/rmat$S.weg, avoiding overwriting." # LOG
		fi
	done
}

build_autoperf()
{
	if [ -z "$SQLITE3" ]; then
		echo "You may need SQLITE3 environment variable for autoperf. Trying to get it with dpkg."
		export SQLITE3=$(dirname $(dpkg -L libsqlite3-dev | grep .so)) # Needed for autoperf
		if [ -z "$SQLITE3" ]; then
			echo "Unable to find libsqlite3 shared object file"
			return 1
		fi
	fi
	if [ -z "$PAPI" ]; then
		echo "Please set the PAPI environment variable"
		return 1
	fi
	# Download autoperf and add it to your PATH
	AUTOPERF_LOC=$(command -v autoperf) # Check if autoperf is already in path
	if [ $? -ne 0 ]; then
		echo "Installing autoperf"
		git clone https://github.com/HPCL/autoperf.git "$HOME/autoperf"
		cd "$HOME/autoperf"
		python setup.py install --user
	else
		echo "found autoperf at $AUTOPERF_LOC"
	fi
}

build_Galois()
{
	GALOIS_DIR="$LIB_DIR/Galois-2.2.1"
    module load boost-1.63.0-gcc-4.8-hucoocn
    cd "$GALOIS_DIR/build"
    mkdir -p release
    cd release
    cmake -DCMAKE_Fortran_COMPILER=gfortran-4.8 ../../ 
}

build_PBBS()
{
	# TODO
	echo "Assumes PBBS is built in the right place."
}

# Build XPS. This also sort of generates the data (though derived from the previous datasets)
build_XPS()
{
	git clone https://github.com/HPCL/xpscode.git "$LIB_DIR/xpscode" # Requires authentication
	cd "$LIB_DIR/xpscode/WorkingCode"
	ESSENSPATH="$LIB_DIR/xpscode/ESSENS"
	mkdir -p "$DDIR/XPS"
	S=16
	# Use vim syntax to edit the Makefile so it has the correct path to ESSENS
	ex -s Makefile "+:%s?^ESSENS=.*?ESSENS=$ESSENSPATH?g" '+:wq'
	make all # This only builds the mst update executable (a.out)
	make cE
	make tEx
	make lpath
	make permF
	# TODO: Get this consistent
	# Usage: ../RMAT/driverForRmat <SCALE> <SC-WT> <a b c d> <Output filename>
	# Details: SCALE = #Vertices = 2^SCALE  -- #Edges = 8*#Vertices
	# SC-WT: Ramdom weights in the range zero to 2^SC-WT will be assigned
	../RMAT/driverForRmat ${S} 5 0.57 0.19 0.19 0.05 "$DDIR/xps-rmat${S}.wel"
	awk '{print $1 " " $2 " " int(rand()*100)}' "$DDIR/xps-rmat${S}.wel" > tmp
	sort -n -k1 -k2 tmp > "$DDIR/xps-rmat${S}.wel" # XXX We don't want to have to sort this.
	rm tmp

	# Create the MST Tree and the Remaining Graph
	# Create the RMAT file, scale ${S}	
	# ./tEx <filename> <starts with 1 or 0>
	./tEx.out "$DDIR/xps-rmat${S}.wel" $(awk '{print $1; exit}' "$DDIR/xps-rmat${S}.wel")
	# This will create three files
	# Graphall.txt (Original file, starting from 0, undirected)
	# GraphC.txt  (the certificate files, MST/BFS)
	# Graphdiff.txt  (remaining edges, not in certificate)

	# Store the generated files with correct names
	mv Graphall.txt "$DDIR/XPS/rmat${S}.wel"
	mv GraphC.txt "$DDIR/XPS/rmat${S}.changes"
	mv Graphdiff.txt "$DDIR/XPS/rmat${S}.diff"

	# Create set of changed Edges  (create_edgelist.cpp)
	# ./cE.out <filename> <number of edges>
	./cE.out "$DDIR/XPS/rmat${S}.wel" 500 > "$DDIR/XPS/changedrmat${S}_500"

	# Sort the edges for faster run
	# sort -n -k1 <filename> > output
	sort -n -k1 -k2 "$DDIR/XPS/changedrmat${S}_500" > "$DDIR/XPS/changedRMAT${S}_500S"

	# The last step: actually run the update
	# Run the update (main_code1.cpp)
	# ./a.out <diff_file> <certificate> <set of changed edges>  <number of vertices>  <number of threads>
	# ./a.out "$DDIR/XPS/rmat18.diff" "$DDIR/XPS/rmat18.changes" "$DDIR/XPS/changedrmat18_500S" 262144 4
}

run_autoperf()
{
	autoperf
}

# Execute
if [ "$cmd" = generate_data -o "$cmd" = all ]; then
	generate_data
fi
if [ "$cmd" = build -o "$cmd" = all ]; then
	build_autoperf
    build_Galois
	build_PBBS
	build_XPS
fi
if [ "$cmd" = autoperf -o "$cmd" = all ]; then
	run_autoperf
fi

