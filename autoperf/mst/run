#!/bin/bash
# Runs mst experiments on Arya
# This should be run in the easy-parallel-graph/autoperf/mst directory

USAGE="usage: ./run generate_data|experiment|all
	. run build <------ do this one first"
# source run build to get the environment variables to stick.

# Parse command line options
cmd="$1"
if [ -z "$cmd" -o "$cmd" = "-h" -o "$cmd" = "--help" ]; then
	echo "$USAGE"
	return 2
elif [ "$cmd" != generate_data -a "$cmd" != experiment -a "$cmd" != build -a "$cmd" != all ]; then
	echo "Invalid argument $cmd"
	echo "$USAGE"
	return 2
fi

# Initialization
# These should all be the same as what's available in autoperf.cfg.
# This is why some are exported and you must source run build
LIB_DIR="$(pwd)/lib"
module load tau # Also loads the PAPI environment variable
export POWER_PROFILING=1
export TAU_MAKEFILE="$TAU_DIR/x86_64/lib/Makefile.tau-papi-pdt-openmp" # I don't think this is needed when sampling
export DDIR=/home/users/spollard/graphalytics/all-datasets/PBBSInput
PBBS_DIR="$LIB_DIR/pbbs-msf/minSpanningForest"
XPS_DIR="$LIB_DIR/xpscode/MSTSC"
ROOTDIR="$(pwd)/output"
SCALES="16 18 20" # Make sure to have SCALES be the same as what's in autoperf.cfg

# Define commands to be run
generate_data()
{
	for S in $SCALES; do
		N_VERT=$(echo 2 ^ $S | bc)
		# TODO: Change from a default 8 to other values.
		M_EDGE=$(echo $N_VERT '*' 8 | bc) # Graph500 spec is 16, XPS code has 8 by default
		WEL_FILE="$DDIR/rmat$S.wel"
		if [ -r "$WEL_FILE" ]; then
			echo "files already exists at $DDIR/rmat$S.*, avoiding overwriting." # LOG
			continue
		fi
		# Make .wel (for XPS and conversion to .gr)
		# Usage: ../RMAT/driverForRmat <SCALE> <SC-WT> <a b c d> <Output filename>
		# Details: SCALE = #Vertices = 2^SCALE  -- #Edges = 8*#Vertices
		# SC-WT: Random weights in the range zero to 2^SC-WT will be assigned
		cd "$XPS_DIR"
		echo "create RMAT with 2^$S vertices and ~8 x 2^$S edges at $DDIR/xps-rmat${S}.wel" # LOG
		../RMAT/driverForRmat ${S} 6 0.25 0.25 0.25 0.25 "$DDIR/xps-rmat${S}.wel"

		# tEx.out requires the first line to begin with 0 or 1
		awk '{print $1 " " $2 " " int(rand()*100)}' "$DDIR/xps-rmat${S}.wel" > tmp
		sort -n -k1 -k2 tmp > "$DDIR/xps-rmat${S}.wel" # XXX We don't want to have to sort this.
		rm tmp

		# Create the MST Tree and the Remaining Graph
		# ./tEx <filename> <starts with 1 or 0>
		./tEx.out "$DDIR/xps-rmat${S}.wel" $(awk '{print $1; exit}' "$DDIR/xps-rmat${S}.wel") # XXX: 2nd arg may not be 0 or 1 (but seems to be so with a=b=c=d=0.25 rmat parameters)
		# This will create three files
		# Graphall.txt (Original file, starting from 0, undirected)
		# GraphC.txt  (the certificate files, MST/BFS)
		# Graphdiff.txt  (remaining edges, not in certificate)
		# Store the generated files with correct names
		mv Graphall.txt "$DDIR/rmat${S}.wel"
		mv GraphC.txt "$DDIR/rmat${S}.cert"
		mv Graphdiff.txt "$DDIR/rmat${S}.diff"

		# Create set of changed Edges  (create_edgelist.cpp)
		# ./cE.out <filename> <number of edges> <maximum weight of new edges> <Percentage of inserted edges (0 to 100)>
		./cE.out "$DDIR/rmat${S}.wel" 500 100 80 > "$DDIR/changedrmat${S}_500"

		# Sort the edges for faster run
		# sort -n -k1 <filename> > output
		sort -n -k1 -k2 "$DDIR/changedrmat${S}_500" > "$DDIR/changedrmat${S}_500S"
		# Example update (what we are timing)
		# ./a.out <diff_file> <certificate> <changed edges>  <max edge weight in complete graph> <num vertices>  <num threads>
		cd "$LIB_DIR/.."

		# Make .weg (for PBBS)
		echo -e "WeightedEdgeArray\n$(cat $DDIR/rmat$S.wel)" > "$DDIR/rmat$S.weg"
		echo "saved to $DDIR/rmat$S.weg" # LOG

		# Make .gr file for Galois
		"$GALOIS_DIR/build/release/tools/graph-convert/graph-convert" -doubleedgelist2gr "$DDIR/rmat$S.wel" "$DDIR/rmat$S.gr"
		"$GALOIS_DIR/build/release/tools/graph-convert/graph-convert" -doubleedgelist2gr "$DDIR/xps-rmat$S.wel" "$DDIR/xps-rmat$S.gr"
	done
	echo "Downloading datasets. May take a while..." # LOG
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-friendster.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-orkut.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-lj.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/soc-pokec-relationships.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/wiki-Talk.txt.gz
	wget -nc -P "$DDIR" http://string-db.org/download/protein.links.v10.txt.gz
}

build_autoperf()
{
	if [ -z "$SQLITE3" ]; then
		echo "You may need SQLITE3 environment variable for autoperf. Trying to get it with dpkg..."
		export SQLITE3=$(dirname $(dpkg -L libsqlite3-dev | grep .so)) # Needed for autoperf
		if [ -z "$SQLITE3" ]; then
			echo "Unable to find libsqlite3 shared object file"
			echo "Try installing libsqlite3-dev or -devel"
			return 1
		fi
	fi
	if [ -z "$PAPI" ]; then
		echo "Please set the PAPI environment variable"
		return 1
	fi
	# Download autoperf and add it to your PATH
	AUTOPERF_LOC=$(command -v autoperf) # Check if autoperf is already in path
	if [ $? -ne 0 ]; then
		echo "Installing autoperf"
		git clone https://github.com/HPCL/autoperf.git "$HOME/autoperf"
		cd "$HOME/autoperf"
		python setup.py install --user
	else
		echo "found autoperf at $AUTOPERF_LOC"
	fi
}

build_Galois()
{
	# XXX: This probably won't work for anyone else.
	# Assumes Galois is already downloaded and unzippeed into GALOIS_DIR
	# This can be found at
	# http://iss.ices.utexas.edu/projects/galois/downloads/Galois-2.2.1.tar.gz
	GALOIS_DIR="$LIB_DIR/Galois-2.2.1"
    module load boost-1.63.0-gcc-4.8-hucoocn
	# Copy from easy-parallel-graph's RAPL wrappers.
	cp -r "$LIB_DIR/../../../power" "$GALOIS_DIR"
	# This must be included in the CMakeLists.txt:
	# if(POWER_PROFILING)
	# 	message(STATUS "Compiling for power measurement using RAPL")
	# 	add_subdirectory(power)
	# 	set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DPOWER_PROFILING=1")
	# 	set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -DPOWER_PROFILING=1")
	# endif()
	# TODO: Get power profiling for Galois
	# 	Should follow the guilde in easy-parallel-graph/power/README.md
	# 	and then adjust it for Cmake (make sure to have proper -I and -L
	# 	directories, as well as getting PAPI_HOME set)
    cd "$GALOIS_DIR/build"
    # mkdir -p release
    # cd release
	mkdir -p power
	cd power
    cmake -DCMAKE_Fortran_COMPILER=gfortran-4.8 -DPOWER_PROFILING=1 ../../ 
}

build_PBBS()
{
	echo "building PBBS..."
	mkdir -p "$PBBS_DIR"
	wget -nc http://www.cs.cmu.edu/~pbbs/benchmarks/minSpanningForest.tar $PBBS_DIR
	if [ ! -d minSpanningForest ]; then
		tar -xvf minSpanningForest.tar
	fi
	cd minSpanningForest/parallelKruskal
	make
	cd "$LIB_DIR/.."
}

# Build XPS. This also sort of generates the data (though derived from the previous datasets)
build_XPS()
{
	git clone https://github.com/HPCL/xpscode.git "$LIB_DIR/xpscode" # Requires authentication
	cd "$XPS_DIR"
	ESSENSPATH="$LIB_DIR/xpscode/ESSENS"
	# Use vim syntax to edit the Makefile so it has the correct path to ESSENS
	ex -s Makefile "+:%s?^ESSENS=.*?ESSENS=$ESSENSPATH?g" '+:wq' # XXX: Will the * cause problems?
	# Turn on power monitoring (CFLAGS is used in c++ code too in this makefile)
	# XXX: May need to put -lpapi at the end
	RAPL_DIR="$LIB_DIR/../../../power"
	POWER_CFLAGS="-w -I$PAPI/include -I$RAPL_DIR -DPOWER_PROFILING=1"
	RAPL_INC="power_rapl.o $RAPL_DIR/power_rapl.h -L$PAPI/lib -Wl,-rpath,$PAPI/lib -lpapi"
	gcc -c $POWER_CFLAGS "$RAPL_DIR/power_rapl.c" -o power_rapl.o
	make CFLAGS="$POWER_CFLAGS" RAPL_INC="$RAPL_INC" all # This only builds the mst update executable (a.out)
	make cE
	make tEx
}

run_autoperf()
{
	# FOR EXAMPLE...
	# TODO: Loop over these in a reasonable way, make AUTOPERF_NUM_THREADS actually done in autoperf.
	AUTOPERF_SCALE=20
	AUTOPERF_CHANGED_EDGES=500
	AUTOPERF_MAX_WEIGHT=100
	AUTOPERF_NUM_VERTICES=$(echo '2 ^ ' $AUTOPERF_SCALE | bc)
	AUTOPERF_EDGES_PER_VERTEX=8 # XXX: Keep this at 8 for now
	AUTOPERF_NUM_THREADS=4

	# NOTE: When using ex you cannot also have that program open in vim or else it will hang
	cp autoperf.cfg .autoperf.cfg # Autoperf searches for .autoperf.cfg first
	ex -s .autoperf.cfg "+:%s/AUTOPERF_SCALE/$AUTOPERF_SCALE/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_CHANGED_EDGES/$AUTOPERF_CHANGED_EDGES/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_MAX_WEIGHT/$AUTOPERF_MAX_WEIGHT/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_NUM_VERTICES/$AUTOPERF_NUM_VERTICES/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_EDGES_PER_VERTEX/$AUTOPERF_EDGES_PER_VERTEX/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_NUM_THREADS/$AUTOPERF_NUM_THREADS/g" '+:wq'
	# autoperf
}

run_experiment()
{
	echo "Running the experiment..."
	cd "$ROOTDIR" # So we can just print output to cwd
	# TODO: Loop over these
	export OMP_NUM_THREADS=2
	S=18
	N_VERT=$(echo 2 ^ $S | bc)
	EPV=8 # Edges Per Vertex

	# Run Galois
	"$GALOIS_DIR/release/apps/boruvka/boruvka" -t=$OMP_NUM_THREADS "$DDIR/rmat$S.gr"
	
	# Run XPS
	# ./a.out <diff_file> <certificate> <set of changed edges>  <number of vertices>  <number of threads>
	"$XPS_DIR/a.out" "$DDIR/rmat$S.diff" "$DDIR/rmat$S.cert" "$DDIR/changedrmat${S}_500S" $N_VERT $OMP_NUM_THREADS
}

if [ "$cmd" = generate_data -o "$cmd" = all ]; then
	generate_data
fi
if [ "$cmd" = build -o "$cmd" = all ]; then
	build_autoperf
    build_Galois
	build_PBBS
	build_XPS
	cd "$LIB_DIR/.."
fi
if [ "$cmd" = experiment -o "$cmd" = all ]; then
	run_autoperf
	# run_experiment
fi

