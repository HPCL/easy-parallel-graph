#!/bin/bash
# Runs mst experiments on Arya
# This should be run in the easy-parallel-graph/autoperf/mst directory

USAGE="usage: ./run [--power] generate_data|experiment|parse|all
	. run [--power] build <------ do this one first"
# source run build to get the environment variables to stick.

# Parse command line options
unset POWER_PROFILING
for arg in "$@"; do
	case $arg in
	--power)
		export POWER_PROFILING=1
		shift
	;;
	*)	# Default
		# Do nothing
	esac
done
cmd="$1"
if [ -z "$cmd" -o "$cmd" = "-h" -o "$cmd" = "--help" ]; then
	echo "$USAGE"
	return 2
elif [ "$cmd" != generate_data -a "$cmd" != experiment -a "$cmd" != build -a "$cmd" != all -a "$cmd" != parse ]; then
	echo "Invalid argument $cmd"
	echo "$USAGE"
	return 2
fi

# Initialization
# These should all be the same as what's available in autoperf.cfg.
# This is why some are exported and you must source run build
LIB_DIR="$(pwd)/lib"
module load tau # Also loads the PAPI environment variable
export TAU_MAKEFILE="$TAU_DIR/x86_64/lib/Makefile.tau-papi-pdt-openmp" # I don't think this is needed when sampling
export DDIR=/home/users/spollard/graphalytics/all-datasets/PBBSInput
PBBS_DIR="$LIB_DIR/pbbs-msf/minSpanningForest"
XPS_DIR="$LIB_DIR/xpscode/MSTSC"
GALOIS_DIR="$LIB_DIR/Galois-2.2.1"
OUTPUTDIR="$(pwd)/output"
ENSURE_CONNECTED='no' # yes if you want to run bfs.out
EPV=8 # Edges per vertex
export OMP_NUM_THREADS=32 # If any generator is multithreaded

# The datasets have been generated for these values.
# This is temporary for the experiment.
RT_TYPES="ER B G"
INS_PCTAGES="10 25 50 75 90 100"
CHANGED_VERTICES="1000 2000 5000"
SCALES="20 21 22 23 24"

# Default settings
# Right now run experiment only loops through SCALES and THREADS
THREADS="2 4 8 16 32"
RT=ER
INS_PCT=75
CVERTS=5000
S=20

# Define commands to be run
generate_data()
{
	echo "Downloading datasets. May take a while..." # LOG
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-friendster.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-orkut.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/bigdata/communities/com-lj.ungraph.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/soc-pokec-relationships.txt.gz
	wget -nc -P "$DDIR" https://snap.stanford.edu/data/wiki-Talk.txt.gz
	wget -nc -P "$DDIR" http://string-db.org/download/protein.links.v10.txt.gz

	# Download or generate Mew MST graph files
	# Right now we just generate them on the fly
	# wget -nc -P "$DDIR" http://brix.d.cs.uoregon.edu/graphs/rmat{20..27}8_{B,G,ER}.gr.gz
	# echo "Unzipping files..."
	# for RT in $RT_TYPES; do
	# 	for S in $SCALES; do
	# 		gunzip -c "$DDIR/rmat${S}${EPV}_${RT}.gr.gz" | awk '{printf "%d %d %d\n",$1,$2,int(rand()*100)}' > "$DDIR/rmat${S}${EPV}_${RT}-orig.wel"
	# 		"$GALOIS_DIR/build/release/tools/graph-convert/graph-convert" -intedgelist2gr "$DDIR/rmat${S}${EPV}_${RT}-orig.wel" "$DDIR/rmat${S}${EPV}_${RT}-orig.wel"
	# 	done
	# done
	cd "$XPS_DIR"
	echo "Generating RMAT files..."
	for RT in $RT_TYPES; do
		for S in $SCALES; do
			echo -e "~~~~~\nGenerating scale $S, $EPV edges per vertex, RMAT $RT\n~~~~~" # LOG
			PART_SUFFIX="${S}${EPV}_${RT}"
			if [ "$RT" = ER ]; then # Just do this once
				"$XPS_DIR/../RMAT/driverForRmat" $S 6 $EPV 0.45 0.15 0.15 0.25 "$DDIR/rmat${S}${EPV}_G-orig.wel"
				"$XPS_DIR/../RMAT/driverForRmat" $S 6 $EPV 0.55 0.15 0.15 0.15 "$DDIR/rmat${S}${EPV}_B-orig.wel"
				"$XPS_DIR/../RMAT/driverForRmat" $S 6 $EPV 0.25 0.25 0.25 0.25 "$DDIR/rmat${S}${EPV}_ER-orig.wel"
			fi
			mv "$DDIR/rmat${PART_SUFFIX}-orig.wel" tmp
			awk '{printf "%d %d %d\n", $1, $2, int(rand()*100)}' tmp > "$DDIR/rmat${PART_SUFFIX}-orig.wel"
			rm tmp
			"$XPS_DIR/tEx.out" "$DDIR/rmat${PART_SUFFIX}-orig.wel" $(awk '{print $1; exit}' "$DDIR/rmat${PART_SUFFIX}-orig.wel")
			# tEx.out generates Graph*x.txt, bfs.out generates Graph*.txt
			if [ "$ENSURE_CONNECTED" = 'yes' ]; then
				echo "WARNING: ENSURE_CONNECTED may not be supported anymore"
				"$XPS_DIR/bfs.out" "$XPS_DIR/GraphCx.txt" $(awk '{print $1; exit}' "$XPS_DIR/GraphCx.txt")
				rm "$XPS_DIR/Graphallx.txt" # May not be connected
				mv "$XPS_DIR/Graphall.txt" "$DDIR/rmat${PART_SUFFIX}.wel"
				rm "$XPS_DIR/GraphCx.txt" # Duplicate
				mv "$XPS_DIR/GraphC.txt" "$DDIR/rmat${PART_SUFFIX}.cert"
				rm "$XPS_DIR/Graphdiff.txt" # Empty
				mv "$XPS_DIR/Graphdiffx.txt" "$DDIR/rmat${PART_SUFFIX}.diff"
			else	
				mv "$XPS_DIR/Graphall.txt" "$DDIR/rmat${PART_SUFFIX}.wel"
				mv "$XPS_DIR/GraphC.txt" "$DDIR/rmat${PART_SUFFIX}.cert"
				mv "$XPS_DIR/Graphdiff.txt" "$DDIR/rmat${PART_SUFFIX}.diff"
			fi
			for INS_PCT in $INS_PCTAGES; do
				for CVERTS in $CHANGED_VERTICES; do	
					echo -e "~~~\n$INS_PCT% insertions, $CVERTS changed vertices\n~~~" # LOG
					FULL_SUFFIX="${S}${EPV}_${RT}_${INS_PCT}i_${CVERTS}"
					"$XPS_DIR/cE.out" "$DDIR/rmat${PART_SUFFIX}.wel" ${CVERTS} 100 $INS_PCT > "$DDIR/changedrmat${FULL_SUFFIX}"
					sort -n -k1 -k2 "$DDIR/changedrmat${FULL_SUFFIX}" > "$DDIR/changedrmat${FULL_SUFFIX}S"
					awk -f "$LIB_DIR/../change_edgelist.awk" -v CEL="$DDIR/changedrmat${FULL_SUFFIX}S" "$DDIR/rmat${PART_SUFFIX}.wel" > "$DDIR/rmat${FULL_SUFFIX}.wel"
					"$GALOIS_DIR/build/release/tools/graph-convert/graph-convert" -intedgelist2gr "$DDIR/rmat${FULL_SUFFIX}.wel" "$DDIR/rmat${FULL_SUFFIX}.gr"
				done
			done
		done
	done
	cd "$LIB_DIR/.."
}

build_autoperf()
{
	if [ -z "$SQLITE3" ]; then
		echo "You may need SQLITE3 environment variable for autoperf. Trying to get it with dpkg..."
		export SQLITE3=$(dirname $(dpkg -L libsqlite3-dev | grep .so)) # Needed for autoperf
		if [ -z "$SQLITE3" ]; then
			echo "Unable to find libsqlite3 shared object file"
			echo "Try installing libsqlite3-dev or -devel"
			return 1
		fi
	fi
	if [ -z "$PAPI" ]; then
		echo "Please set the PAPI environment variable"
		return 1
	fi
	# Download autoperf and add it to your PATH
	AUTOPERF_LOC=$(command -v autoperf) # Check if autoperf is already in path
	if [ $? -ne 0 ]; then
		echo "Installing autoperf"
		git clone https://github.com/HPCL/autoperf.git "$HOME/autoperf"
		cd "$HOME/autoperf"
		python setup.py install --user
	else
		echo "found autoperf at $AUTOPERF_LOC"
	fi
}

build_Galois()
{
	# XXX: This probably won't work for anyone else.
	#
	# This must be added to the CMakeLists.txt:
	# if(POWER_PROFILING)
	#   message(STATUS "Compiling for power measurement using RAPL")
	#   set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DPOWER_PROFILING=1 -L${PAPI}/lib -Wl,-rpath,${PAPI}/lib")
	#   set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -DPOWER_PROFILING=1 -L${PAPI}/lib -Wl,-rpath,${PAPI}/lib")
	#   include_directories("${PAPI}/include")
	# endif()
	#
	# Replace apps/boruvka/CMakeLists.txt with the following:
	# app(boruvka Boruvka.cpp power_rapl.c power_rapl.h
	#   EXTLIBS papi)
	# app(boruvka-merge BoruvkaMerge.cpp)
	
	# Replace
	# Assumes Galois is already downloaded and unzipped into GALOIS_DIR
	# This can be found at
	# http://iss.ices.utexas.edu/projects/galois/downloads/Galois-2.2.1.tar.gz
	# The newer the version of boost, the newer you must have of cmake
    # module load boost-1.63.0-gcc-4.8-hucoocn
	module load boost/boost_1_53_0_gcc-4.8
	# Copy from easy-parallel-graph's RAPL wrappers.
    cd "$GALOIS_DIR/build"
	if [ "$POWER_PROFILING" = "1" ]; then
		mkdir -p power
		cd power
		cp "$LIB_DIR/../../../power/power_rapl.c" "$GALOIS_DIR/apps/boruvka"
		cp "$LIB_DIR/../../../power/power_rapl.h" "$GALOIS_DIR/apps/boruvka"
		cmake -DCMAKE_Fortran_COMPILER=gfortran-4.8 -DPOWER_PROFILING=1 -DPAPI="$PAPI" -Wno-dev ../../ 
	else
		mkdir -p release
		cd release
		cmake -DCMAKE_Fortran_COMPILER=gfortran-4.8 -Wno-dev ../../ 
	fi
}

build_PBBS()
{
	echo "building PBBS..."
	mkdir -p "$PBBS_DIR"
	wget -nc -P "$PBBS_DIR/.." http://www.cs.cmu.edu/~pbbs/benchmarks/minSpanningForest.tar 
	if [ ! -d minSpanningForest ]; then
		tar -xf minSpanningForest.tar
	fi
	cd minSpanningForest/parallelKruskal
	make
	cd "$LIB_DIR/.."
}

# Build XPS. This also sort of generates the data (though derived from the previous datasets)
build_XPS()
{
	git clone https://github.com/HPCL/xpscode.git "$LIB_DIR/xpscode" # Requires authentication
	cd "$XPS_DIR"
	ESSENSPATH="$LIB_DIR/xpscode/ESSENS"
	# Use vim syntax to edit the Makefile so it has the correct path to ESSENS
	ex -s Makefile "+:%s?^ESSENS=.*?ESSENS=$ESSENSPATH?g" '+:wq' # XXX: Will the * cause problems?
	# Turn on power monitoring (CFLAGS is used in c++ code too in this makefile)
	if [ "$POWER_PROFILING" = "1" ]; then
		CC=gcc
		RAPL_DIR="$LIB_DIR/../../../power"
		POWER_CFLAGS="-w -I$PAPI/include -I$RAPL_DIR -DPOWER_PROFILING=1"
		RAPL_INC="power_rapl.o $RAPL_DIR/power_rapl.h -L$PAPI/lib -Wl,-rpath,$PAPI/lib -lpapi"
		$CC -c $POWER_CFLAGS "$RAPL_DIR/power_rapl.c" -o power_rapl.o
		make CFLAGS="$POWER_CFLAGS" RAPL_INC="$RAPL_INC" all # This only builds the mst update executable (a.out)
	else
		make all
	fi
	make cE
	make tEx
	make bfs
}

run_autoperf()
{
	# FOR EXAMPLE...
	# TODO: Loop over these in a reasonable way, make AUTOPERF_NUM_THREADS actually done in autoperf.
	echo "CAUTION: Incomplete."
	AUTOPERF_SCALE=20
	AUTOPERF_CHANGED_EDGES=500
	AUTOPERF_MAX_WEIGHT=100
	AUTOPERF_NUM_VERTICES=$(echo '2 ^ ' $AUTOPERF_SCALE | bc)
	AUTOPERF_EDGES_PER_VERTEX=8 # XXX: Keep this at 8 for now
	AUTOPERF_NUM_THREADS=4

	# NOTE: When using ex you cannot also have that program open in vim or else it will hang
	cp autoperf.cfg .autoperf.cfg # Autoperf searches for .autoperf.cfg first
	ex -s .autoperf.cfg "+:%s/AUTOPERF_SCALE/$AUTOPERF_SCALE/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_CHANGED_EDGES/$AUTOPERF_CHANGED_EDGES/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_MAX_WEIGHT/$AUTOPERF_MAX_WEIGHT/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_NUM_VERTICES/$AUTOPERF_NUM_VERTICES/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_EDGES_PER_VERTEX/$AUTOPERF_EDGES_PER_VERTEX/g" '+:wq'
	ex -s .autoperf.cfg "+:%s/AUTOPERF_NUM_THREADS/$AUTOPERF_NUM_THREADS/g" '+:wq'
	# autoperf
}

run_experiment()
{
	echo "Running the experiment..."
	mkdir -p "$OUTPUTDIR"
	cd "$OUTPUTDIR" # So we can just print output to cwd
	# TODO: more parameters and more loop levels
	# Adjust parameters
	SD='sudo'
	if [ "$POWER_PROFILING" = "1" ]; then
		GALOIS_MST="$GALOIS_DIR/build/power/apps/boruvka/boruvka"
	else
		GALOIS_MST="$GALOIS_DIR/build/release/apps/boruvka/boruvka"
		SD=''
	fi
	for OMP_NUM_THREADS in $THREADS; do
		export OMP_NUM_THREADS
		for S in $SCALES; do
			N_VERT=$(echo 2 ^ $S | bc)
			FULL_SUFFIX="${S}${EPV}_${RT}_${INS_PCT}i_${CVERTS}"
			PART_SUFFIX="${S}${EPV}_${RT}"
			MSTLOG="$OUTPUTDIR/mst-${S}${EPV}_$RT_${INS_PCT}i_${CVERTS}_${OMP_NUM_THREADS}t.log"
			GALOISLOG="$OUTPUTDIR/galois-${S}${EPV}_$RT_${INS_PCT}i_${CVERTS}_${OMP_NUM_THREADS}t.log"
			$SD "$GALOIS_MST" -t=$OMP_NUM_THREADS "$DDIR/rmat${FULL_SUFFIX}.gr" | tee "$GALOISLOG"
			# ./a.out <diff_file> <certificate> <set of changed edges> <upper bound of edge weight> <number of vertices>  <number of threads>
			$SD "$XPS_DIR/a.out" "$DDIR/rmat${PART_SUFFIX}.diff" "$DDIR/rmat${PART_SUFFIX}.cert" "$DDIR/changedrmat${FULL_SUFFIX}S" 100 $N_VERT $OMP_NUM_THREADS | tee "$MSTLOG"
			$SD chown $USER "$MSTLOG"
			$SD chown $USER "$GALOISLOG"
		done
	done
	cd "$LIB_DIR/.."
}

# parse_output helper function: parse one output file
# Expects the following variables to be set:
# PKG DATA_FORMAT GALOISLOG MSTLOG PFN
parse_one()
{
	if [ "$POWER_PROFILING" = "1" ]; then
		# Galois
		awk -v PKG=$PKG -v INFO="$DATA_FORMAT" '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "Galois,All,%s,Total CPU Energy (J),%s\n",INFO,t+$3;t=0}else{t+=$3}}' "${GALOISLOG}" >> "$PFN"
		awk -v PKG=$PKG -v INFO="$DATA_FORMAT" '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "Galois,All,%s,Average CPU Power (W),%s\n",INFO,t+$3;t=0}else{t+=$3}}' "${GALOISLOG}" >> "$PFN"
		awk -v PKG=$PKG -v INFO="$DATA_FORMAT" '/^[0-9]+\.[0-9]+ s/{printf "Galois,All,%s,RAPL Time (s),%s\n",INFO,$1;exit}' ${GALOISLOG} >> "$PFN"
		# MST
		awk -v PKG=$PKG -v INFO="$DATA_FORMAT" '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,%s,All,Total CPU Energy (J),%s\n",INFO,t+$3;t=0}else{t+=$3}}' "${MSTLOG}" >> "$PFN"
		awk -v PKG=$PKG -v INFO="$DATA_FORMAT" '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,%s,All,Average CPU Power (W),%s\n",INFO,t+$3;t=0}else{t+=$3}}' "${MSTLOG}" >> "$PFN"
		awk -v PKG=$PKG -v INFO="$DATA_FORMAT" '/^[0-9]+\.[0-9]+ s/{printf "MST,%s,All,RAPL Time (s),%s\n",INFO,$1;exit}' "${MSTLOG}" >> "$PFN"
	fi
	# Galois
	awk -F ',' -v INFO="$DATA_FORMAT" '/,Time,/{printf "Galois,All,%s,Time (s),%s\n",INFO,$5 / 1000}' "${GALOISLOG}" >> "$PFN"
	# MST
	awk -v INFO="$DATA_FORMAT" '/Time for First Pass/{printf "MST,first pass,%s,Time (s),%s\n",INFO,$5}' "${MSTLOG}" >> "$PFN"
	awk -v INFO="$DATA_FORMAT" '/Time for Insertion/{printf "MST,insertion,%s,Time (s),%s\n",INFO,$4}' "${MSTLOG}" >> "$PFN"
	awk -v INFO="$DATA_FORMAT" '/Time for Deletion/{printf "MST,deletion,%s,Time (s),%s\n",INFO,$4}' "${MSTLOG}" >> "$PFN"
	awk -v INFO="$DATA_FORMAT" '/Time for Updating/{printf "MST,All,%s,Time (s),%s\n",INFO,$6}' "${MSTLOG}" >> "$PFN"
}

parse_output()
{
	echo "Parsing output..."
	if [ "$POWER_PROFILING" = "1" ]; then
		PFN="$OUTPUTDIR/parsed-power-aggregate.txt"
	else
		PFN="$OUTPUTDIR/parsed-aggregate.txt"
	fi
	RT=ER # RMAT type: ER->(.25,.25,.25,.25) G->(.45, .15, .15, .25) B->(.55, .15, .15, .15)
	PKG=2
	# Print the header. XXX: Should this be > instead of >>?
	echo 'algorithm,execution_phase,scale,edges_per_vertex,RMAT_type,insertion_percent,changed_vertices,threads,measurement,value' >> "$PFN"
	for RT in $RT_TYPES; do
		for S in $SCALES; do
			for INS_PCT in $INS_PCTAGES; do
				for CVERTS in $CHANGED_VERTICES; do	
					for T in $THREADS; do
						for S in $SCALES; do
							MSTLOG="$OUTPUTDIR/mst-${S}${EPV}_$RT_${INS_PCT}i_${CVERTS}_${T}t.log"
							GALOISLOG="$OUTPUTDIR/galois-${S}${EPV}_$RT_${INS_PCT}i_${CVERTS}_${T}t.log"
							DATA_FORMAT="$S,$EPV,$RT,$INS_PCT,$CVERTS,$T"
							parse_one
						done
					done
				done
			done
		done
	done
}
# Old parse output
# The extra steps for grep are unnecessary since we save each run in a different file.
			# grep -A 30 'Starting create_tree' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,create_tree,%s_%s_%s,Average CPU Power (W),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			# grep -A 30 'Starting create_tree' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,create_tree,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' >> "$PFN"

			# grep -A 30 'Starting first_pass' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,first_pass,%s_%s_%s,Total CPU Energy (J),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			# grep -A 30 'Starting first_pass' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,first_pass,%s_%s_%s,Average CPU Power (W),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			# grep -A 30 'Starting first_pass' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,first_pass,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' >> "$PFN"

			# grep -A 30 'Starting process_insertions' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,process_insertions,%s_%s_%s,Total CPU Energy (J),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			# grep -A 30 'Starting process_insertions' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,process_insertions,%s_%s_%s,Average CPU Power (W),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			# grep -A 30 'Starting process_insertions' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,process_insertions,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' >> "$PFN"

			# grep -B 31 'Time for Deletion' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Total Energy.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,process_deletions,%s_%s_%s,Total CPU Energy (J),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			# grep -B 31 'Time for Deletion' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/Average.*PACKAGE_ENERGY:PACKAGE[0-9]+ \*/{c++;if(c%PKG==0){printf "MST,process_deletions,%s_%s_%s,Average CPU Power (W),%f\n",S,EPV,RMT,t+$3;t=0}else{t+=$3}}' >> "$PFN"
			# grep -B 31 'Time for Deletion' ${MSTLOG} | awk -v PKG=$PKG -v S=$S -v EPV=$EPV -v RMT=$RT '/^[0-9]+\.[0-9]+ s/{printf "MST,process_deletions,%s_%s_%s,Time (s),%s\n",S,EPV,RMT,$1;exit}' >> "$PFN"

###
# "Main"
###
if [ "$cmd" = generate_data -o "$cmd" = all ]; then
	generate_data
fi
if [ "$cmd" = build -o "$cmd" = all ]; then
	build_autoperf
    build_Galois
	# build_PBBS
	build_XPS
	cd "$LIB_DIR/.."
fi

if [ "$cmd" = parse -o "$cmd" = all ]; then
	parse_output
fi

if [ "$cmd" = experiment -o "$cmd" = all ]; then
	# run_autoperf
	run_experiment
fi

